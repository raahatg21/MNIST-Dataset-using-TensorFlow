{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_TF_1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/raahatg21/MNIST-Dataset-using-TensorFlow/blob/master/1_Logistic_Regression.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "HE7G0z5BROXl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# MNIST Dataset: Logistic Regression"
      ]
    },
    {
      "metadata": {
        "id": "2yNY4JD9BjYy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Classification on MNIST Dataset using basic Logistic Regression using TensorFlow. Test Accuracy: 90.9%"
      ]
    },
    {
      "metadata": {
        "id": "PH0a9VEuPO9R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X0Jw2scmTUtN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "bd3904fc-3a2a-4da3-ac68-f7df7aeb221c"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-2-02b855d8d526>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-JPr0QKzTtgo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "da58fd15-acac-471d-8348-368b385cdb79"
      },
      "cell_type": "code",
      "source": [
        "# Setup to use TensorBoard in Google Colab\n",
        "\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Redirecting output to ‘wget-log.2’.\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gW09tEzKUWVX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LOG_DIR = './log'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nvc-RdZYUb2H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oD2uer6IUlbq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0c18feb1-a185-47ff-c6e3-13f1277d0f60"
      },
      "cell_type": "code",
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://b7699ea6.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "auPastjDUqUR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Defining Hyperparameters\n",
        "\n",
        "learning_rate = 0.05\n",
        "batch_size = 100\n",
        "max_epochs = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n0LwQe6wU46c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Defining Placeholders\n",
        "\n",
        "X = tf.placeholder(tf.float32, [None, 784])\n",
        "Y = tf.placeholder(tf.float32, [None, 10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XT8eCDx8VFpn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Defining weights and bias variables\n",
        "\n",
        "w = tf.Variable(tf.zeros([784, 10]))\n",
        "b = tf.Variable(tf.zeros([10]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gxusg6hhVRIV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Defining Logistic Regression function\n",
        "\n",
        "with tf.name_scope(\"wx_b\") as scope:\n",
        "  Y_hat = tf.nn.softmax(tf.matmul(X, w) + b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CXsg7SKcVgkF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Defining Summary Ops\n",
        "\n",
        "w_h = tf.summary.histogram(\"weights\", w)\n",
        "b_h = tf.summary.histogram(\"bias\", b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MiOIkkBgV0K7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "2b6b7b68-cd61-4695-c808-b6ab41ec2e43"
      },
      "cell_type": "code",
      "source": [
        "# Defining Cross-entropy Loss\n",
        "\n",
        "with tf.name_scope(\"Cross-entropy\") as scope:\n",
        "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = Y, logits = Y_hat))\n",
        "  tf.summary.scalar(\"cross-entropy\", loss)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-12-2cd4e6ea376c>:3: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1QZUEcWeWUT_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Defining the Optimiser\n",
        "\n",
        "with tf.name_scope(\"Train\") as scope:\n",
        "  optimizer = tf.train.GradientDescentOptimizer(0.01).minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lr9tGjzvWutp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Defining the Metric\n",
        "\n",
        "correct_preds = tf.equal(tf.argmax(Y_hat, 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_preds, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lpuuZ8cBXBSb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uOb2kdjgXInQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "merged_summary_op = tf.summary.merge_all()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3wCyMK8NXNOj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1771
        },
        "outputId": "c0ac2a4c-7bc6-4b24-c9cb-aa1d6068e0fa"
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  summary_writer = tf.summary.FileWriter('./log', sess.graph)\n",
        "  for epoch in range(max_epochs):\n",
        "    loss_avg = 0\n",
        "    batches = int(mnist.train.num_examples/batch_size)\n",
        "    for i in range(batches):\n",
        "      batch_X, batch_y = mnist.train.next_batch(100)\n",
        "      _, l, summary_str = sess.run([optimizer, loss, merged_summary_op], feed_dict = {X: batch_X, Y: batch_y})\n",
        "      loss_avg += l\n",
        "      summary_writer.add_summary(summary_str, epoch*batches + i)\n",
        "    loss_avg /= batches\n",
        "    print(\"Epoch {0}: Loss {1}\".format(epoch, loss_avg))\n",
        "  print(sess.run(accuracy, feed_dict = {X: mnist.test.images, Y: mnist.test.labels}))  # Testing"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: Loss 2.250564671429721\n",
            "Epoch 1: Loss 2.090633141560988\n",
            "Epoch 2: Loss 1.9618487366763029\n",
            "Epoch 3: Loss 1.8837388279221274\n",
            "Epoch 4: Loss 1.8339531850814819\n",
            "Epoch 5: Loss 1.8018444043939763\n",
            "Epoch 6: Loss 1.7797444731538945\n",
            "Epoch 7: Loss 1.7635171842575073\n",
            "Epoch 8: Loss 1.7510183134945956\n",
            "Epoch 9: Loss 1.741039398800243\n",
            "Epoch 10: Loss 1.732857296033339\n",
            "Epoch 11: Loss 1.7259958605332808\n",
            "Epoch 12: Loss 1.7201332725178111\n",
            "Epoch 13: Loss 1.715064808888869\n",
            "Epoch 14: Loss 1.710604773868214\n",
            "Epoch 15: Loss 1.7066512881625782\n",
            "Epoch 16: Loss 1.7031118219549006\n",
            "Epoch 17: Loss 1.6999069287560202\n",
            "Epoch 18: Loss 1.696993340362202\n",
            "Epoch 19: Loss 1.6943008262460881\n",
            "Epoch 20: Loss 1.6918259371410718\n",
            "Epoch 21: Loss 1.689484751224518\n",
            "Epoch 22: Loss 1.6872497454556552\n",
            "Epoch 23: Loss 1.685051904591647\n",
            "Epoch 24: Loss 1.6827242961796847\n",
            "Epoch 25: Loss 1.6798880202120001\n",
            "Epoch 26: Loss 1.6753045151450416\n",
            "Epoch 27: Loss 1.6682640647888183\n",
            "Epoch 28: Loss 1.662254932793704\n",
            "Epoch 29: Loss 1.6575556412610142\n",
            "Epoch 30: Loss 1.653161983273246\n",
            "Epoch 31: Loss 1.6489648079872132\n",
            "Epoch 32: Loss 1.6449820184707642\n",
            "Epoch 33: Loss 1.641263160055334\n",
            "Epoch 34: Loss 1.637853762886741\n",
            "Epoch 35: Loss 1.63477303721688\n",
            "Epoch 36: Loss 1.6320296116308732\n",
            "Epoch 37: Loss 1.6295857028527694\n",
            "Epoch 38: Loss 1.6273957668651233\n",
            "Epoch 39: Loss 1.6254148723862387\n",
            "Epoch 40: Loss 1.6236311758648265\n",
            "Epoch 41: Loss 1.6219820963252674\n",
            "Epoch 42: Loss 1.620459599494934\n",
            "Epoch 43: Loss 1.6190325643799521\n",
            "Epoch 44: Loss 1.617698489969427\n",
            "Epoch 45: Loss 1.616438373002139\n",
            "Epoch 46: Loss 1.6152501091090115\n",
            "Epoch 47: Loss 1.614118613763289\n",
            "Epoch 48: Loss 1.6130379991097883\n",
            "Epoch 49: Loss 1.612010344808752\n",
            "Epoch 50: Loss 1.6110269370946018\n",
            "Epoch 51: Loss 1.6100853490829468\n",
            "Epoch 52: Loss 1.6091815558346836\n",
            "Epoch 53: Loss 1.6083068401163274\n",
            "Epoch 54: Loss 1.6074718169732527\n",
            "Epoch 55: Loss 1.60666404875842\n",
            "Epoch 56: Loss 1.6058875695141879\n",
            "Epoch 57: Loss 1.6051320180025967\n",
            "Epoch 58: Loss 1.6044085335731506\n",
            "Epoch 59: Loss 1.6036988145654851\n",
            "Epoch 60: Loss 1.6030163736776872\n",
            "Epoch 61: Loss 1.6023555040359496\n",
            "Epoch 62: Loss 1.6017148798162286\n",
            "Epoch 63: Loss 1.6010859682343224\n",
            "Epoch 64: Loss 1.6004821237650784\n",
            "Epoch 65: Loss 1.5998938931118358\n",
            "Epoch 66: Loss 1.5993196118961681\n",
            "Epoch 67: Loss 1.5987620895559138\n",
            "Epoch 68: Loss 1.5982178170030767\n",
            "Epoch 69: Loss 1.597688151923093\n",
            "Epoch 70: Loss 1.597171051718972\n",
            "Epoch 71: Loss 1.596667455326427\n",
            "Epoch 72: Loss 1.5961744737625123\n",
            "Epoch 73: Loss 1.5956899573586203\n",
            "Epoch 74: Loss 1.5952251601219176\n",
            "Epoch 75: Loss 1.5947614992748607\n",
            "Epoch 76: Loss 1.5943161420388656\n",
            "Epoch 77: Loss 1.593875274441459\n",
            "Epoch 78: Loss 1.59344191421162\n",
            "Epoch 79: Loss 1.593025683706457\n",
            "Epoch 80: Loss 1.5926135052334178\n",
            "Epoch 81: Loss 1.5922088334777138\n",
            "Epoch 82: Loss 1.5918154621124267\n",
            "Epoch 83: Loss 1.5914283990859985\n",
            "Epoch 84: Loss 1.5910482508485968\n",
            "Epoch 85: Loss 1.5906697275421837\n",
            "Epoch 86: Loss 1.5903074195168234\n",
            "Epoch 87: Loss 1.5899522623148832\n",
            "Epoch 88: Loss 1.5895961178432811\n",
            "Epoch 89: Loss 1.589253619367426\n",
            "Epoch 90: Loss 1.5889105478200045\n",
            "Epoch 91: Loss 1.588578727245331\n",
            "Epoch 92: Loss 1.5882504138079556\n",
            "Epoch 93: Loss 1.5879264200817456\n",
            "Epoch 94: Loss 1.5876109489527617\n",
            "Epoch 95: Loss 1.5873018273440274\n",
            "Epoch 96: Loss 1.586993284225464\n",
            "Epoch 97: Loss 1.586691114252264\n",
            "Epoch 98: Loss 1.5863979213887995\n",
            "Epoch 99: Loss 1.5861047846620733\n",
            "0.909\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2fJO34rKZLjG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}